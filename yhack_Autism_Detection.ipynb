{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FO4sCP4rB3lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwe2jnkw0LF1",
        "outputId": "d95ba6e9-0784-4b9e-aa02-0c1e8667abc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr  9 22:45:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hvcEEoQRfTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1e2515-7962-4575-fdd3-102e210a397f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-9QgjKo1ZmX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-5ACvXIT9Df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc556aad-8b68-4296-f1de-98441bd14a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset  output.avi  train.txt\tweights_0.params  weights_9.params\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/yhacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpgHVulT1arW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3351fcdf-9e24-46a7-9ba1-6074459ce0a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "Collecting mxnet-cu101==1.7.0\n",
            "  Downloading mxnet_cu101-1.7.0-py2.py3-none-manylinux2014_x86_64.whl (846.0 MB)\n",
            "\u001b[K     |███████████████████████████████▌| 834.1 MB 1.4 MB/s eta 0:00:09tcmalloc: large alloc 1147494400 bytes == 0x563341942000 @  0x7fa47c5c7615 0x563307c2217c 0x563307d0247a 0x563307c24f9d 0x563307d16d4d 0x563307c98ec8 0x563307c93a2e 0x563307c2688a 0x563307c98d30 0x563307c93a2e 0x563307c2688a 0x563307c95719 0x563307d17b76 0x563307c94d95 0x563307d17b76 0x563307c94d95 0x563307d17b76 0x563307c94d95 0x563307c26ce9 0x563307c6a579 0x563307c25902 0x563307c98c4d 0x563307c93a2e 0x563307c2688a 0x563307c95719 0x563307c93a2e 0x563307c2688a 0x563307c948f6 0x563307c267aa 0x563307c94b4f 0x563307c93a2e\n",
            "\u001b[K     |████████████████████████████████| 846.0 MB 22 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101==1.7.0) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101==1.7.0) (1.21.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2.10)\n",
            "Installing collected packages: graphviz, mxnet-cu101\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu101-1.7.0\n",
            "Collecting gluoncv\n",
            "  Downloading gluoncv-0.10.5-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gluoncv) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.4.1)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gluoncv) (7.1.2)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.21.5)\n",
            "Collecting autocfg\n",
            "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.63.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.1.2.30)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->gluoncv) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->gluoncv) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (1.24.3)\n",
            "Installing collected packages: yacs, portalocker, autocfg, gluoncv\n",
            "Successfully installed autocfg-0.0.8 gluoncv-0.10.5 portalocker-2.4.0 yacs-0.1.8\n",
            "Collecting decord\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.6 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from decord) (1.21.5)\n",
            "Installing collected packages: decord\n",
            "Successfully installed decord-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version \n",
        "!pip install -U mxnet-cu101==1.7.0    \n",
        "#version was 1.7.0\n",
        "!pip install --upgrade gluoncv\n",
        "!pip install decord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxS277HA1a1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d95f9a-9d68-4066-8026-835f29ab5117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.7.0` and `torch==1.10.0+cu111` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
            "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from __future__ import division\n",
        "\n",
        "import argparse, time, logging, os, sys, math\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas\n",
        "from decord import VideoReader\n",
        "\n",
        "import mxnet as mx\n",
        "import gluoncv \n",
        "from mxnet import gluon, nd, init, context\n",
        "from mxnet import autograd as ag\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "\n",
        "from gluoncv.data.transforms import video\n",
        "from gluoncv.data import VideoClsCustom\n",
        "import gluoncv.data \n",
        "from gluoncv.model_zoo import get_model\n",
        "from gluoncv.utils import makedirs, LRSequential, LRScheduler, split_and_load, TrainingHistory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlDbFVeNHW_I"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlbQh0WWHTb8"
      },
      "source": [
        "TRAIN DATA GENRATOR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53ZzhYwe1a8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "439b0348-7d4f-4f90-a207-39500275119a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load 10 training samples.\n"
          ]
        }
      ],
      "source": [
        "#https://medium.com/apache-mxnet/gluoncv-0-6-embrace-video-understanding-49bc10ec1421\n",
        "\n",
        "num_gpus = 1\n",
        "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    # Fix the input video frames size as 256×340 and randomly sample the cropping width and height from\n",
        "    # {256,224,192,168}. After that, resize the cropped regions to 224 × 224.\n",
        "    video.VideoMultiScaleCrop(size=(224, 224), scale_ratios=[1.0, 0.9]), #WAS THIS  scale_ratios=[1.0, 0.875, 0.75, 0.66]\n",
        "    # Randomly flip the video frames horizontally\n",
        "    video.VideoRandomHorizontalFlip(),\n",
        "    # Transpose the video frames from height*width*num_channels to num_channels*height*width\n",
        "    # and map values from [0, 255] to [0,1]\n",
        "    video.VideoToTensor(),\n",
        "    # Normalize the video frames with mean and standard deviation calculated across all images\n",
        "    #video.VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "per_device_batch_size = 2 #change batch size over here \n",
        "num_workers = 0 # these two lines are used if we were trying to use multiple gpus - so ignore\n",
        "batch_size = per_device_batch_size * num_gpus\n",
        "\n",
        "train_dataset = VideoClsCustom(root=os.path.expanduser('/content/drive/MyDrive/yhacks/'),#bounded_videos/'),\n",
        "                               setting=os.path.expanduser('/content/drive/MyDrive/yhacks/train.txt'),  #CHANGE\n",
        "                               train=True,\n",
        "                               video_loader=True,\n",
        "                               use_decord=True,\n",
        "                               #video_ext = 'mp4',\n",
        "                               new_length=80,\n",
        "                              #  slowfast=True,\n",
        "                              #  slow_temporal_stride=8,\n",
        "                              #  fast_temporal_stride=2,\n",
        "                              #  new_height = 224,\n",
        "                              # new_width= 224,\n",
        "                               transform=transform_train\n",
        "                               )\n",
        "print('Load %d training samples.' % len(train_dataset))\n",
        "train_data = gluon.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                   shuffle=True, num_workers=num_workers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5zjCa1BHYGv"
      },
      "source": [
        "VAL DATA GENERATOR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLOxBBBvHave",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87b8188-94d0-4fd7-9c7c-651f7d4a331b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load 10 training samples.\n"
          ]
        }
      ],
      "source": [
        "# #https://medium.com/apache-mxnet/gluoncv-0-6-embrace-video-understanding-49bc10ec1421\n",
        "\n",
        "num_gpus = 1\n",
        "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    # Fix the input video frames size as 256×340 and randomly sample the cropping width and height from\n",
        "    # {256,224,192,168}. After that, resize the cropped regions to 224 × 224.\n",
        "    video.VideoMultiScaleCrop(size=(224, 224), scale_ratios=[1.0, 0.9]), #WAS THIS  scale_ratios=[1.0, 0.875, 0.75, 0.66]\n",
        "    # Randomly flip the video frames horizontally\n",
        "    video.VideoRandomHorizontalFlip(),\n",
        "    # Transpose the video frames from height*width*num_channels to num_channels*height*width\n",
        "    # and map values from [0, 255] to [0,1]\n",
        "    video.VideoToTensor(),\n",
        "    # Normalize the video frames with mean and standard deviation calculated across all images\n",
        "   # video.VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "per_device_batch_size =16 #change batch size over here \n",
        "num_workers = 0 # these two lines are used if we were trying to use multiple gpus - so ignore\n",
        "batch_size = per_device_batch_size * num_gpus\n",
        "\n",
        "val_dataset = VideoClsCustom(root=os.path.expanduser('/content/drive/MyDrive/yhacks/'),#bounded_videos/'),\n",
        "                               setting=os.path.expanduser('/content/drive/MyDrive/yhacks/train.txt'),  #CHANGE\n",
        "                               train=False,\n",
        "                               video_loader=True,\n",
        "                               use_decord=True,\n",
        "                               #video_ext = 'mp4',\n",
        "                               new_length=80,\n",
        "                              #  slowfast=True,\n",
        "                              #  slow_temporal_stride=8,\n",
        "                              #  fast_temporal_stride=2,\n",
        "                              #  new_height = 224,\n",
        "                              # new_width= 224,\n",
        "                               transform=transform_train\n",
        "                               )\n",
        "\n",
        "\n",
        "print('Load %d training samples.' % len(val_dataset))\n",
        "val_data = gluon.data.DataLoader(val_dataset, batch_size=batch_size,\n",
        "                                   shuffle=True, num_workers=num_workers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEptzunA3bXs"
      },
      "source": [
        "\n",
        "will get erroe if you set pretrained = true. Instead you should set pretrained_base = true as we are changing the number of classes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abnVKSzwMtHE"
      },
      "outputs": [],
      "source": [
        "# url = f\"https://raw.githubusercontent.com/dmlc/gluon-cv/6818c3270454e8262dff3088d2c5a9ad742294d3/gluoncv/model_zoo/action_recognition/slowfast.py\"\n",
        "# !wget --no-cache --backups=1 {url} \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMzI3pNaNCrx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import slowfast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkLrtAYb3MO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8205d83b-38ef-462f-9c0e-cff98e03aa1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.mxnet/models/resnet50_v1b-0ecdba34.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet50_v1b-0ecdba34.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55344/55344 [00:01<00:00, 37602.33KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv0_weight is done with shape:  (64, 3, 5, 7, 7)\n",
            "batchnorm0_gamma is done with shape:  (64,)\n",
            "batchnorm0_beta is done with shape:  (64,)\n",
            "batchnorm0_running_mean is done with shape:  (64,)\n",
            "batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_0_conv0_weight is done with shape:  (64, 64, 3, 1, 1)\n",
            "layer1_0_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_0_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_0_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_0_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_0_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer1_downsample_conv0_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_downsample_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_beta is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer1_1_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
            "layer1_1_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_1_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_1_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_1_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_1_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer1_2_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
            "layer1_2_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_2_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_2_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_2_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_2_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer2_0_conv0_weight is done with shape:  (128, 256, 3, 1, 1)\n",
            "layer2_0_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_0_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_0_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_0_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_0_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_downsample_conv0_weight is done with shape:  (512, 256, 1, 1, 1)\n",
            "layer2_downsample_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_beta is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer2_1_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
            "layer2_1_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_1_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_1_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_1_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_1_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_2_conv0_weight is done with shape:  (128, 512, 3, 1, 1)\n",
            "layer2_2_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_2_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_2_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_2_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_2_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_3_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
            "layer2_3_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_3_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_3_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_3_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_3_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer3_0_conv0_weight is done with shape:  (256, 512, 3, 1, 1)\n",
            "layer3_0_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_0_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_0_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_0_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_0_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_downsample_conv0_weight is done with shape:  (1024, 512, 1, 1, 1)\n",
            "layer3_downsample_batchnorm0_gamma is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_beta is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_running_mean is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_running_var is done with shape:  (1024,)\n",
            "layer3_1_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_1_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_1_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_1_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_1_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_1_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_2_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
            "layer3_2_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_2_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_2_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_2_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_2_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_3_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_3_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_3_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_3_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_3_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_3_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_4_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
            "layer3_4_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_4_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_4_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_4_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_4_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_5_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_5_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_5_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_5_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_5_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_5_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer4_0_conv0_weight is done with shape:  (512, 1024, 1, 1, 1)\n",
            "layer4_0_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_0_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_0_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_0_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_0_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_running_var is done with shape:  (2048,)\n",
            "layer4_downsample_conv0_weight is done with shape:  (2048, 1024, 1, 1, 1)\n",
            "layer4_downsample_batchnorm0_gamma is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_beta is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_running_mean is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_running_var is done with shape:  (2048,)\n",
            "layer4_1_conv0_weight is done with shape:  (512, 2048, 3, 1, 1)\n",
            "layer4_1_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_1_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_1_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_1_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_1_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_running_var is done with shape:  (2048,)\n",
            "layer4_2_conv0_weight is done with shape:  (512, 2048, 1, 1, 1)\n",
            "layer4_2_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_2_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_2_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_2_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_2_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_running_var is done with shape:  (2048,)\n",
            "dense0_weight is skipped with shape:  (2, 2048)\n",
            "dense0_bias is skipped with shape:  (2,)\n",
            "Downloading /root/.mxnet/models/i3d_resnet50_v1_kinetics400-568a722e.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/i3d_resnet50_v1_kinetics400-568a722e.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 208483/208483 [00:11<00:00, 18177.46KB/s]\n"
          ]
        }
      ],
      "source": [
        "#net = gluoncv.model_zoo.slowfast_4x16_resnet50_kinetics400(nclass=50, pretrained_base=True, num_segments=1, ctx=ctx)#check num_segments\n",
        "#net = get_model(name='i3d_resnet50_v1_custom', nclass=2)\n",
        "#kinetics_model = get_model(name='slowfast_8x8_resnet101_kinetics400', nclass=400, pretrained=True)\n",
        "net = get_model(name='i3d_resnet50_v1_custom',nclass=2,pretrained=False,pretrained_base=True,feat_ext=False,partial_bn=True)\n",
        "\n",
        "                   \n",
        "                     \n",
        "                    \n",
        "\n",
        "# source_params = kinetics_model.collect_params()\n",
        "# target_params = net.collect_params()\n",
        "# assert len(source_params.keys()) == len(target_params.keys())\n",
        "\n",
        "# pretrained_weights=[]\n",
        "# for layer_name in source_params.keys():\n",
        "#     pretrained_weights.append(source_params[layer_name].data())\n",
        "\n",
        "# for i, layer_name in enumerate(target_params.keys()):\n",
        "#     if i + 2 == len(source_params.keys()):\n",
        "#         # skip the last dense layer\n",
        "#         break\n",
        "#     target_params[layer_name].set_data(pretrained_weights[i])\n",
        "\n",
        "# net.collect_params().reset_ctx(ctx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qJAna6-5-ST"
      },
      "outputs": [],
      "source": [
        "# net.summary\n",
        "# or print(net) , both work "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO3AFFYZid_0"
      },
      "outputs": [],
      "source": [
        "# mx.viz.plot_network(net(mx.sym.var('data'))[0], node_attrs={\"shape\":\"oval\",\"fixedsize\":\"false\"},hide_weights=False,save_format='pdf').render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tncqoHCJjGMU"
      },
      "outputs": [],
      "source": [
        "\n",
        "net.collect_params().reset_ctx(ctx)\n",
        "net.collect_params().reset_ctx(mx.Context('cpu'))\n",
        "net.load_parameters('/content/drive/MyDrive/yhacks/weights_9.params')\n",
        "net.collect_params().reset_ctx(mx.Context('gpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMxhlgHJPh3o"
      },
      "outputs": [],
      "source": [
        "net.collect_params().setattr('grad_req', 'null')\n",
        "\n",
        "\n",
        "# net.res_layers[3].collect_params().setattr('grad_req', 'write')\n",
        "# net.res_layers[2].collect_params().setattr('grad_req', 'write')\n",
        "# net.st_avg.collect_params().setattr('grad_req', 'write')\n",
        "net.head.collect_params().setattr('grad_req', 'write')\n",
        "net.fc.collect_params().setattr('grad_req', 'write')\n",
        "net.collect_params().reset_ctx(mx.Context('gpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpA4ZN3n6jvi"
      },
      "outputs": [],
      "source": [
        "net.hybridize()\n",
        "warmup_epoch = 2\n",
        "total_epoch = 10\n",
        "num_batches = len(train_data)\n",
        "\n",
        "scheduler=mx.lr_scheduler.CosineScheduler(max_update=total_epoch, base_lr=1e-4, final_lr=1e-6, warmup_steps=warmup_epoch,  warmup_mode='constant',warmup_begin_lr=1e-4)\n",
        "\n",
        "# lr_scheduler = LRSequential([\n",
        "#     LRScheduler('linear', base_lr=0.1, target_lr=0.12,\n",
        "#                 nepochs=warmup_epoch, iters_per_epoch=num_batches),\n",
        "#     LRScheduler('cosine', base_lr=0.12, target_lr=0,\n",
        "#                 nepochs=total_epoch - warmup_epoch,\n",
        "#                 iters_per_epoch=num_batches,\n",
        "#                 step_factor=lr_decay, power=2)\n",
        "# ])\n",
        "# Stochastic gradient descent\n",
        "optimizer = 'Adam'#mxnet.optimizer.Adam(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, )\n",
        "# Set parameters\n",
        "#optimizer_params = {'learning_rate':  0.005}  #,'wd': 0.0001, 'momentum': 0.9}\n",
        "#optimizer_params['lr_scheduler'] = lr_scheduler\n",
        "optimizer_params = {'wd': 1e-4}  #,'wd': 0.0001,\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define our trainer for net\n",
        "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)#the set of parameters to optimize\n",
        "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "train_metric = mx.metric.Accuracy()\n",
        "val_metric = mx.metric.Accuracy()\n",
        "train_history = TrainingHistory(['training-acc']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrzGzVkJVf3J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "2e5176e7-3aa5-466d-d5de-6318e72b4e59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fee79cc1a10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(columns=['epoch','lr'])\n",
        "for i in range(total_epoch):\n",
        "  dictionary = {'epoch':i,'lr':scheduler(i)}\n",
        "  df = df.append(dictionary,ignore_index=True)\n",
        "  #print(optimizer.learning_rate)\n",
        "df.plot(x = 'epoch', y = 'lr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFG7iGVT-Uoa"
      },
      "source": [
        "\n",
        "valid_acc = metric.Accuracy()\n",
        "for data,label in valid_data:\n",
        "    output = network(data)\n",
        "    valid_acc.update(label,output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4at9Q40qZRs_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "6aeb2abd-771c-46f6-e25c-919845ef4fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0] train=0.900000 loss=0.676221 lr=0.000100 time: 6.306873\n",
            "[Epoch 1] train=0.800000 loss=0.683104 lr=0.000100 time: 6.329958\n",
            "[Epoch 2] train=1.000000 loss=0.662342 lr=0.000100 time: 6.686812\n",
            "[Epoch 3] train=0.900000 loss=0.670496 lr=0.000096 time: 6.061710\n",
            "[Epoch 4] train=1.000000 loss=0.651996 lr=0.000086 time: 5.734033\n",
            "[Epoch 5] train=0.700000 loss=0.657466 lr=0.000069 time: 6.006545\n",
            "[Epoch 6] train=0.900000 loss=0.658228 lr=0.000051 time: 7.413042\n",
            "[Epoch 7] train=0.800000 loss=0.676052 lr=0.000032 time: 5.969315\n",
            "[Epoch 8] train=0.800000 loss=0.672363 lr=0.000015 time: 5.896529\n",
            "[Epoch 9] train=0.900000 loss=0.663253 lr=0.000005 time: 5.910499\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "epochs = total_epoch\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    lr = scheduler(epoch)\n",
        "    trainer.set_learning_rate(lr)\n",
        "    tic = time.time()\n",
        "    train_metric.reset()\n",
        "    val_metric.reset()\n",
        "    train_loss = 0\n",
        "\n",
        "    # Loop through each batch of training data\n",
        "    for i, batch in enumerate(train_data):\n",
        "        # Extract data and label\n",
        "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "        # AutoGrad\n",
        "        with ag.record():\n",
        "            output = []\n",
        "            for _, X in enumerate(data):\n",
        "                X = X.reshape((-1,) + X.shape[2:])\n",
        "                pred = net(X)\n",
        "                output.append(pred)\n",
        "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
        "\n",
        "        # Backpropagation\n",
        "        for l in loss:\n",
        "            l.backward()\n",
        "\n",
        "        # Optimize\n",
        "        trainer.step(batch_size)\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss += sum([l.mean().asscalar() for l in loss])\n",
        "        train_metric.update(label, output)\n",
        "\n",
        "        #if i == 100:\n",
        "         #   break\n",
        "\n",
        "    name, acc = train_metric.get()\n",
        "\n",
        "    #--------------------------------------------------------------------------\n",
        "    # for i, batch in enumerate(val_data):\n",
        "    #     # Extract data and label\n",
        "    #     data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "    #     label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "        \n",
        "    #     val_output = []\n",
        "    #     for _, X in enumerate(data):\n",
        "    #         X = X.reshape((-1,) + X.shape[2:])\n",
        "    #         pred = net(X)\n",
        "    #         val_output.append(pred)\n",
        "            \n",
        "   \n",
        "    #     val_metric.update(label, val_output)\n",
        "    # name_val, val_acc = val_metric.get()\n",
        "\n",
        "    # Update history and print metrics\n",
        "    train_history.update([acc])\n",
        "    # print('[Epoch %d] train=%f val=%f loss=%f lr=%f time: %f' %\n",
        "    #     (epoch, acc, val_acc, train_loss / (i+1),trainer.learning_rate, time.time()-tic))\n",
        "    print('[Epoch %d] train=%f loss=%f lr=%f time: %f' %\n",
        "        (epoch, acc, train_loss / (i+1),trainer.learning_rate, time.time()-tic))\n",
        "    \n",
        "    if epoch%9==0:\n",
        "      x = epoch \n",
        "      file_name = '/content/drive/MyDrive/yhacks/weights_'+str(x)+'.params'\n",
        "      net.save_parameters(file_name)\n",
        "# We can plot the metric scores with:\n",
        "train_history.plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUFhs7iBcUwj"
      },
      "outputs": [],
      "source": [
        "# print(net.slow_res3[0].conv1.weight.data())\n",
        "# print(net.fc.weight.data())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz8m2eBKeh7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9d648c-7b4e-4cf8-afe6-911abaebe739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Child is banging or shaking head continuously and suffering from Autism\n",
            "Child is banging or shaking head continuously and suffering from Autism\n",
            "Child is flapping arms and suffering from Autism\n",
            "Child is banging or shaking head continuously and suffering from Autism\n",
            "Child is banging or shaking head continuously and suffering from Autism\n",
            "Child is flapping arms and suffering from Autism\n",
            "Child is flapping arms and suffering from Autism\n",
            "Child is banging or shaking head continuously and suffering from Autism\n",
            "Child is flapping arms and suffering from Autism\n",
            "Child is flapping arms and suffering from Autism\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "class_str = []\n",
        "class_str_dict = {}\n",
        "for word in os.listdir('/content/drive/MyDrive/yhacks/dataset'):   #CHANGE\n",
        "    class_str.append(word)\n",
        "for work in class_str:\n",
        "  seperate = work.split('_')\n",
        "  # print(seperate)\n",
        "  num = int(seperate[1])\n",
        "  c = str(seperate[0])\n",
        "  class_str_dict[num] =  c\n",
        "  class_str = []\n",
        "# print(class_str_dict)\n",
        "for i in range(len(class_str_dict)):\n",
        "    class_str.append(class_str_dict[i])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import math as m\n",
        "import matplotlib.pyplot as plt\n",
        "k = []\n",
        "for i in range(2):\n",
        "  k.append(i)\n",
        "val_metric = mx.metric.Accuracy()\n",
        "# val2 = mx.metric.TopKAccuracy(top_k = 3)\n",
        "# val3 = mx.metric.TopKAccuracy(top_k = 5)\n",
        "# val3.reset()\n",
        "# val2.reset()\n",
        "val_metric.reset()\n",
        "y_true = []\n",
        "predictions_valid = []\n",
        "y_pred = []\n",
        "# print(len(val_dataset))\n",
        "for i, batch in enumerate(val_data): # here change accordingly whether val or train\n",
        "        \n",
        "        # print(i)\n",
        "        # print(len(val_data))\n",
        "        # if i==m.ceil(len(val_dataset)/16): # declare these 2 variables and also change according with val and train\n",
        "        #   break\n",
        "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "        y_true = y_true + label[0].asnumpy().tolist()\n",
        "        val_output = []\n",
        "        for _, X in enumerate(data):\n",
        "            X = X.reshape((-1,) + X.shape[2:])\n",
        "            # print(X.shape)\n",
        "            # print(type(X))\n",
        "            pred = net(X)\n",
        "            # print(pred.shape)\n",
        "            val_output.append(pred)\n",
        "            predictions_valid  = predictions_valid + pred.asnumpy().tolist()\n",
        "        val_metric.update(label, val_output)\n",
        "        # val2.update(label, val_output)\n",
        "        # val3.update(label, val_output)\n",
        "\n",
        "name_val, val_acc = val_metric.get()\n",
        "# print('val=%f'  %(val_acc))\n",
        "# print(val2)\n",
        "# print(val3)\n",
        " \n",
        "for i in range(0,len(predictions_valid)):\n",
        "    y_pred = y_pred + [np.argmax(predictions_valid[i])]\n",
        "\n",
        "# print(len(y_pred))\n",
        "# print(len(y_true))\n",
        "# print(y_true)\n",
        "# print(y_pred)\n",
        "for i in y_pred:\n",
        "  if i==0:\n",
        "    print(\"Child is flapping arms and suffering from Autism\")\n",
        "  else:\n",
        "    print(\"Child is banging or shaking head continuously and suffering from Autism\")\n",
        "\n",
        "score = accuracy_score(y_true, y_pred)\n",
        "# print('Classification Report: ',classification_report(y_true,y_pred))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "# f,ax= plt.subplots(figsize=(15, 15))\n",
        "# sns.heatmap(cm,annot = True, fmt='g', ax=ax,) #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "\n",
        "#labels, title and ticks\n",
        "#ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
        "#ax.set_title('Confusion Matrix');\n",
        "classes_rev = []\n",
        "\n",
        "classes = k\n",
        "l = 2\n",
        "for i in range(1,l+1):\n",
        "    classes_rev = classes_rev + [classes[l-i]]\n",
        "# ax.xaxis.set_ticklabels(class_str);ax.yaxis.set_ticklabels(class_str);\n",
        "# plt.yticks(rotation='horizontal')\n",
        "# plt.xticks(rotation=90)\n",
        "# ax.xaxis.set_ticklabels(classes);ax.yaxis.set_ticklabels(classes);\n",
        "# ax.figure.savefig(\"confusion_mat_of_i3dres50_1.png\",dpi=500)        #CHANGE FILE NAME \n",
        "# print('Accuracy: ', score)\n",
        "# print('F1',sklearn.metrics.f1_score(y_true, y_pred, average='weighted'))\n",
        "\n",
        "with open('i3dres50_FINAL.txt','w') as ft:       #CHANGE FILEN NAME\n",
        "  for r in cm:\n",
        "   for c in r:\n",
        "      ft.write(str(c))\n",
        "   ft.write('\\n')\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4GkjJxf2SRs"
      },
      "outputs": [],
      "source": [
        "mx.nd.array(numpy_ex_int_array)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.reshape((-1,) + X.shape[2:])\n",
        "print(X.shape)\n",
        "print(type(X))\n",
        "pred = net(X)"
      ],
      "metadata": {
        "id": "LgXq9F4hBZNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sk-video"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBnrOfkUDNLr",
        "outputId": "dcdf9e28-8f98-4497-92fc-0e83ee5db0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sk-video\n",
            "  Downloading sk_video-1.1.10-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 10.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sk-video) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sk-video) (1.4.1)\n",
            "Installing collected packages: sk-video\n",
            "Successfully installed sk-video-1.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import skvideo.io  \n",
        "videodata = skvideo.io.vread(\"drive/MyDrive/yhacks/dataset/armflapping_0/afn2.mp4\")  \n",
        "print(videodata.shape)\n",
        "x = mx.nd.array(videodata)\n",
        "type(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7PpNWTmDE6J",
        "outputId": "8ceda024-1d6f-480d-fb15-0b913e9d0ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(122, 360, 480, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mxnet.ndarray.ndarray.NDArray"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JqdHWhZgDLqa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "yhack_Autism_Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}